\documentclass[twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{subfigure}
\usepackage{hyperref}
\voffset = -100pt
\hoffset = -50pt
\headheight = 0pt
\textwidth = 550pt
\textheight = 750pt
\author{Name Surname }
\setlength{\columnsep}{0.3cm}
\usepackage{blindtext}
\pagestyle{empty}
\footskip = 0pt
\bibliographystyle{plain}

\begin{document}

\section*{Viktor Pavlov 230335TAF}
\section{Music Genre Classification via MFCC Analysis}
\begin{figure}[htbp]
  \centering
  \begin{minipage}[t]{0.5\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{images/audio_jazz.pdf}
  \end{minipage}\hfill
  \begin{minipage}[t]{0.5\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{images/audio_metal.pdf}
  \end{minipage}
  \caption{Audio Waveforms of the files \texttt{jazz.00000.wav} (left) and \texttt{metal.00001.wav} (right).}
  \label{fig:waves}
\end{figure}
The goal of this project is to try music genre classification, utilizing audio feature extraction techniques together with clustering and classification data mining techniques. For this purpose, the GTZAN Genre Collection dataset~\cite{tzanetakis_essl_cook_2001} will be used. The dataset consists of $1000$ audio tracks, each $30$ seconds long. It contains $10$ genres, each represented by $100$ tracks. The tracks are all $22050$ Hz monophonic $16$-bit audio files in \texttt{.au} format. It's important to note, that this is a legacy dataset, collected from various sources, including personal CDs, radio and microphone recordings, with inconsistent quality~\cite{sturm2013gtzan}. Nevertheless, it's sufficient for our use case. Visualizations of audio signals from the dataset are displayed in Figure~\ref{fig:waves}.
\section{MFCC Audio Feature Extraction}
Mel-frequency cepstrum coefficients (MFCCs) are a representation of the audio signal in the form of a unique spectrum. It's known to taking a complex audio signal and translating it into a simplified version that captures the essential components to the human ear. Applications of MFCCs include speech recognition~\cite{ganchev2005comparative} and music genre classification~\cite{lerch2012introduction}. Various literature suggests that the first $12$ coefficients are sufficient for speech recognition, while it's recommended to use $20-40$ coefficients for musical audio signals. The precise number of coefficients can be determined by means of experementation, and in context of this project, the first $30$ coefficients were used. The \texttt{tuneR} package~\cite{tuneR} was utilized for extracting the MFCCs. Visualization of MFCCs is displated in Figure~\ref{fig:mfcc}.
\section{K-Means Clustering}
\begin{figure}[hht]
\centering
\includegraphics[width=0.49\textwidth]{images/mfcc_heatmap_8.pdf}
\caption{MFCC heatmap of the file \texttt{classical.00015.wav}.}
\label{fig:mfcc}
\end{figure}
\blindtext
\section{Classification using Support Vector Machines (SVM)}
\begin{figure}[hht]
	\centering
	\includegraphics[width=0.49\textwidth]{images/clust_class.pdf}
  \caption{Correlation heat map of the Boston Housing dataset.}
	\label{fig:corr}
\end{figure}
\blindtext
\bibliography{bibliography}
\end{document}
